{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a14573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from statsmodels.api import OLS\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89c81aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"day.csv\") #mention your path here; in my case the file is in the same directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d9f5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9253560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6953e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dcaba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming column names for convenience\n",
    "\n",
    "data.rename(columns = {\"mnth\" : \"Month\", \"weathersit\" : \"Weather_condition\", \"hum\" : \"humidity\", \"cnt\" : \"Count\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db9f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f6d077",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(20) # Checking data consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca25a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check for any null columns\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21e7b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's good that we have data which has no null value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9667748",
   "metadata": {},
   "source": [
    "## Cleaning the data and running some Quality Checks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90924743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will encode certain numerics so that we can undrstand and interprete those variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd849f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"weekday\", \"workingday\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ecbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 Means that the day is not a working day(weekends and holdiays) and 1 means that the day is a working day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf71bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the information above we can determine the encodings for weekday and they are as follows\n",
    "# The encodings for month is given to us in data dictionary\n",
    "\n",
    "data[\"Month\"] = data.Month.replace([1,2,3,4,5,6,7,8,9,10,11,12], [\"January\", \"February\", \"March\", \"April\", \"May\",\n",
    "                                                                 \"June\", \"July\", \"August\", \"September\", \"October\",\n",
    "                                                                 \"Novermber\", \"December\"])\n",
    "\n",
    "data[\"weekday\"] = data.weekday.replace([0,1,2,3,4,5,6], [\"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\",\n",
    "                                                        \"Sunday\", \"Monday\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86da800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"dteday\", \"Month\", \"weekday\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa96737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run quality checks on month and weekday \n",
    "# Since there are no null values we should some obivous patterns such as the number of unique months cannot exceed 12 \n",
    "# The number of weekdays cannot exceed 6 as we have encoded tuesday as 0\n",
    "\n",
    "print(f\"Unique months are : {data.Month.unique()} \\n\")\n",
    "\n",
    "print(f\"Number of unique months are :{data.Month.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7255ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Unique weekdays are : {data.weekday.unique()} \\n\")\n",
    "\n",
    "print(f\"Number of unique weekdays are :{data.weekday.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a61fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will drop all our uncessary columns at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d87c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will encode Weather_condition and season and for this we will refer our data dictionary\n",
    "# This will make our data look a little cleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ef4b53",
   "metadata": {},
   "source": [
    "### Deciphering \"Weather_condition\" can be a bit tricky; according to the data dictionary provided to us the following is the decoded information\n",
    " - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "\n",
    "### Just by reading it we can coin our own adjectives to better understand the data in one word\n",
    "- 1 : Ideal\n",
    "- 2 : Misty\n",
    "- 3 : snow_rain\n",
    "- 4 : heavy_snow_rain\n",
    "\n",
    "### For seasons too we will use our data dictionary to coin them\n",
    "- 1:spring \n",
    "- 2:summer\n",
    "- 3:fall\n",
    "- 4:winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7e0c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.Weather_condition.unique())\n",
    "print(data.season.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5021142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It looks like our weather_condition has only recorded 3 types of weather\n",
    "\n",
    "data[\"Weather_condition\"] = data[\"Weather_condition\"].replace([1,2,3,4], [\"ideal\", \"misty\", \"snow_rain\", \"heavy_snow_rain\"])\n",
    "data[\"season\"] = data[\"season\"].replace([1,2,3,4], [\"spring\", \"summer\", \"fall\", \"winter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349d41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique Weather_conditions are : {data.Weather_condition.unique()} \\n\")\n",
    "\n",
    "print(f\"Number of unique Weather_conditions are :{data.Weather_condition.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0833538",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique seasons are : {data.season.unique()} \\n\")\n",
    "\n",
    "print(f\"Number of unique seasons are :{data.season.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1797a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"Weather_condition\", \"season\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d475a9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66326d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will run some quality checks for our numerical columns as well\n",
    "# Although there can exist negative temperatures we wanted to see if our data has any negative values \n",
    "data[data[\"temp\"] <= 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b580b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"atemp\"] <= 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6cb293",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"humidity\"] <= 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac87beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"humidity\"] == 0.0, \"humidity\"] = data[\"humidity\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6893b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"humidity\"] <= 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10652523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windspeed cannot be negative:\n",
    "data[data[\"windspeed\"] <= 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b046bd3",
   "metadata": {},
   "source": [
    "### We ran this code just to see some varaitions of the recorded data and one can see that humidity is 0 which is not possible given the weather condtions on earth, so we can either omit the row or can impute the row i.e is fill that value with the median of that column and since it is only row we will rather impute it\n",
    "\n",
    "### Resource : https://www.google.com/search?client=firefox-b-d&q=can+humidity+be+zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e93ddb3",
   "metadata": {},
   "source": [
    "### We have finished running  quality checks and now we will eliminate redundant columns along with columns which will cause errors in our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b46e3f",
   "metadata": {},
   "source": [
    "### We will drop the columns which we dont need\n",
    "- instant : This is just the record number and clearly is of no use\n",
    "- dteday : Most of the information from this column have been derived in other columns, so this holds little to no value and would be redundant\n",
    "- casual & registered : We will assume we dont know these values while the model predicts on new data and our target -value is simply the sum of these two columns so when we include these in our model, the model will memorize these value and fail to generalize on the given data, in simple term these two values will leak information of our targeted variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1203c794",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"instant\", \"dteday\", \"casual\", \"registered\"]\n",
    "\n",
    "data.drop(cols_to_drop, axis = 1, inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f8045",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b692a4",
   "metadata": {},
   "source": [
    "## Data visualization (EDA)\n",
    "- Check for outliers\n",
    "- Check for some collinearity\n",
    "- Identify and deduce some patterns which helps us to understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ce5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function for our uni-variate, bi-variate and multi-variate(More than two) analysis\n",
    "\n",
    "def plots(x = None, y = None, hues = None, rotation = 0, bar_plot = False, box_plot = False, count_plot = False,\n",
    "         figsisze = (17, 5), fontsize = 10, estimator = np.mean, dataframe = data):\n",
    "    \n",
    "    if bar_plot:\n",
    "        sns.barplot(x = x, y = y, hue = hues, data = dataframe, estimator=estimator)\n",
    "        plt.gcf().set_size_inches(figsisze)\n",
    "        plt.title(label = f\"Bar plot between {x} and {y}\",fontdict = {\"fontsize\" : fontsize})\n",
    "        plt.xlabel(xlabel = str(x), fontsize = fontsize)\n",
    "        plt.ylabel(ylabel = str(y), fontsize = fontsize)\n",
    "        plt.xticks(fontsize = fontsize, rotation = rotation)\n",
    "        plt.yticks(fontsize = fontsize)\n",
    "    \n",
    "    elif box_plot :\n",
    "        sns.boxplot(x = x, y = y, hue = hues, data = dataframe)\n",
    "        plt.gcf().set_size_inches(figsisze)\n",
    "        plt.title(label = f\"Box plot between {x} and {y}\",fontdict = {\"fontsize\" : fontsize})\n",
    "        plt.xlabel(xlabel = str(x), fontsize = fontsize,rotation = rotation)\n",
    "        plt.ylabel(ylabel = str(y), fontsize = fontsize)\n",
    "        plt.xticks(fontsize = fontsize, rotation = rotation)\n",
    "        plt.yticks(fontsize = fontsize)\n",
    " \n",
    "    elif count_plot:\n",
    "        sns.countplot(x = x, hue = hues, data = dataframe)\n",
    "        plt.gcf().set_size_inches(figsisze)\n",
    "        plt.title(label = f\"Count plot between {x} and {y}\",fontdict = {\"fontsize\" : fontsize})\n",
    "        plt.xlabel(xlabel = str(x), fontsize = fontsize, rotation = rotation)\n",
    "        plt.ylabel(ylabel = str(y), fontsize = fontsize)\n",
    "        plt.xticks(fontsize = fontsize, rotation = rotation)\n",
    "        plt.yticks(fontsize = fontsize)\n",
    "    \n",
    "    else :\n",
    "        print(\"Please set the Boolean value to True for any of the following plots : \\n  [bar_plot, box_plot, count_plot]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4d55cd",
   "metadata": {},
   "source": [
    "## Checking for outliers\n",
    "\n",
    "### Since we have only four numerical columns it will be a short work considering that there wont be annoying outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfbf4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_for_boxplot = [\"temp\", \"atemp\", \"humidity\", \"windspeed\"]\n",
    "\n",
    "plt.gcf().set_size_inches(10,9)\n",
    "\n",
    "for i,j in enumerate(cols_for_boxplot):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    sns.boxplot(data = data, y = j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343882ff",
   "metadata": {},
   "source": [
    "## Observations :\n",
    "- There arent any annoying outlier so no need to change or delete any rows\n",
    "- temp and atemp seems to be similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdc3a36",
   "metadata": {},
   "source": [
    "## Checking for some collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4282ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use pairplot to achieve this along with heatmaps\n",
    "\n",
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631d602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.corr(), annot = True)\n",
    "plt.gcf().set_size_inches(10,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a227f4c",
   "metadata": {},
   "source": [
    "## Observation :\n",
    "- temp and atemp shows high collinearity, this could be a problem while building our model\n",
    "- Also there exists some linear relationship between temp and cnt, atemp and cnt\n",
    "- A positive corelation can be observed between yr and cnt as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc30dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp vs count and windspeed vs Count\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.regplot(x = data[\"Count\"], y = data[\"temp\"], line_kws={\"color\" : \"r\"})\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.regplot(x = data[\"Count\"], y = data[\"windspeed\"], line_kws={\"color\" : \"r\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f89d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = data[\"Count\"], y = data[\"temp\"], line_kws={\"color\" : \"r\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074d0eae",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "- A linear relationship can be seen; a positive one in the first plot and a negative one in the second plot\n",
    "- Temp has a postive linear relationship with Count which can be decued from the plot and ehatmap above\n",
    "- Windspeed has a negative moderately linear relationship  with Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a06919",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = data[\"Count\"], y = data[\"humidity\"], line_kws={\"color\" : \"r\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d40319a",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "- We can see a moderately negative correlation between humidity and Count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617be3d8",
   "metadata": {},
   "source": [
    "## Let's visualise our data using bivariate and multi variate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e85008",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1079cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"season\"\n",
    "y = \"Count\"\n",
    "\n",
    "plots(x = x, y = y, bar_plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf57fb5f",
   "metadata": {},
   "source": [
    "## Observations :\n",
    "- Fall and summer shows the highest count \n",
    "- This could be due to the summer vacation which typicall lasts for 2 and a half months\n",
    "- Some students also prefer riding bikes to school which can explain the rise in count in fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d10cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"yr\"\n",
    "y = \"Count\"\n",
    "\n",
    "plots(x = x, y = y, bar_plot = True, fontsize=15)\n",
    "plt.xticks(ticks = [0,1], labels = [\"2018\", \"2019\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cd96fc",
   "metadata": {},
   "source": [
    "## Observations :\n",
    "- The business is growing for Boombikes in 2019 which is a good indicator for the company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d62c0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"Month\"\n",
    "y = \"Count\"\n",
    "\n",
    "plots(x = x, y = y, bar_plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bacdf9",
   "metadata": {},
   "source": [
    "## Observations :\n",
    "- summer runs from June 1 to August 31; fall (autumn) runs from September 1 to November 30 which explains the higher bike count in those months\n",
    "- resource :https://www.google.com/search?client=firefox-b-d&q=summer+and+fall+in+US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d3e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"weekday\"\n",
    "y = \"Count\"\n",
    "plt.subplot(121)\n",
    "plots(x = x, y = y, bar_plot = True)\n",
    "\n",
    "plt.subplot(122)\n",
    "plots(x = x, y = y, box_plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c6bf26",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "- It seems that the count is evenly distributed accross the days of the week\n",
    "- no specific apttern observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc47cca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"workingday\"\n",
    "y = \"Count\"\n",
    "\n",
    "plots(x = x, y = y, bar_plot = True, fontsize=15, estimator=np.median)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3535ca8",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "- No pattern can be uncovered from this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd5e347",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"holiday\"\n",
    "y = \"Count\"\n",
    "\n",
    "plots(x = x, y = y, bar_plot = True, fontsize=15, estimator=np.median)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ff74d",
   "metadata": {},
   "source": [
    "## Observations :\n",
    "- People who tend to be working tend have a higher bike count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949e0a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"Weather_condition\"\n",
    "y = \"Count\"\n",
    "\n",
    "plots(x = x, y = y, bar_plot = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51e4805",
   "metadata": {},
   "source": [
    "## Observations :\n",
    "- People tend to ride bikes when the weather is misty or ideal which makes sense given that the weather condition palys a mojor role in deciding to whether ride a bike or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62011534",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"season\"\n",
    "y = \"Count\"\n",
    "hue = \"yr\"\n",
    "plots(x = x, y = y, bar_plot = True, hues = hue, fontsize=15)\n",
    "labels = plt.legend()\n",
    "labels.get_texts()[0].set_text(\"2018\")\n",
    "labels.get_texts()[1].set_text(\"2019\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bca1e6",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "- As we have already seen that there is year on yeat growth and this is evident across various seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a349005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"Month\"\n",
    "y = \"Count\"\n",
    "hue = \"yr\"\n",
    "plots(x = x, y = y, bar_plot = True, hues = hue, fontsize=15, rotation = 45)\n",
    "\n",
    "labels = plt.legend()\n",
    "labels.get_texts()[0].set_text(\"2018\")\n",
    "labels.get_texts()[1].set_text(\"2019\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c9a954",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "- This plot shows the same results of year on year growth and the growht hasnt dipped when compared to 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae675f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"workingday\"\n",
    "y = \"Count\"\n",
    "hue = \"yr\"\n",
    "plots(x = x, y = y, bar_plot = True, hues = hue)\n",
    "\n",
    "labels = plt.legend()\n",
    "labels.get_texts()[0].set_text(\"2018\")\n",
    "labels.get_texts()[1].set_text(\"2019\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef96b3a0",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "- The same can be said about this plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc166f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"Weather_condition\"\n",
    "y = \"Count\"\n",
    "hue = \"yr\"\n",
    "plots(x = x, y = y, bar_plot = True, hues = hue, fontsize=15)\n",
    "\n",
    "labels = plt.legend()\n",
    "labels.get_texts()[0].set_text(\"2018\")\n",
    "labels.get_texts()[1].set_text(\"2019\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62276e9c",
   "metadata": {},
   "source": [
    "### We have finished with our EDA and now let's beging with building and preparing our data for the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2be384",
   "metadata": {},
   "source": [
    "## Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df58848",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a25285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a38011",
   "metadata": {},
   "source": [
    "### Creating dummy variables for categorical data :- season, Month, weekday and Weather_condition\n",
    "- We do this to improve the computational time and accuracy of our model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6aa8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_season = pd.get_dummies(data[\"season\"], drop_first = True)\n",
    "\n",
    "dummy_Month = pd.get_dummies(data[\"Month\"], drop_first = True)\n",
    "\n",
    "dummy_weekday = pd.get_dummies(data[\"weekday\"], drop_first = True)\n",
    "\n",
    "dummy_Weather_condition = pd.get_dummies(data[\"Weather_condition\"], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf2d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_season\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcb198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e0276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccce332",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_Weather_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32425a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's concatenate this to our original data but we will spare changes in the orignal data\n",
    "# We will create a new variable which stores all the data\n",
    "\n",
    "data1 = pd.concat([data, dummy_season, dummy_Month, dummy_weekday, dummy_Weather_condition], axis = 1)\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f8eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's time to drop the original columns\n",
    "\n",
    "data1.drop([\"season\", \"Month\", \"weekday\", \"Weather_condition\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b45b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79ed8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78293986",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25,20))\n",
    "\n",
    "sns.heatmap(data1.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2bd2a2",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "- Temp and atemp are almost perfectly correlated almost and each of them have the same correlation with  our targeted variable Count which means that one of the two is enough to represent temperature\n",
    "- Yr is also positively correalated with Count as we saw an increase in count as year progresses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1592bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.drop(\"atemp\", axis= 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8324edc",
   "metadata": {},
   "source": [
    "### Feature Scaling our numerical data:- temp, atemp, humidity, Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f930c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split the data into training and test set before we scale otherwise we risk leaking data into our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bed093",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data1, train_size = 0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d83625",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d491b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25,20))\n",
    "\n",
    "sns.heatmap(train_df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950defdc",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "- We can see high negavtive and positive correlation\n",
    "- We need to be carefull whiloe buidling our models although majority if the data seems to have low correlation;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8123ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() # We will use Normalization to scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05329d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_vars = [\"temp\", \"humidity\", \"windspeed\", \"Count\"]\n",
    "\n",
    "train_df[numerical_vars] = scaler.fit_transform(train_df[numerical_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390bb85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[numerical_vars].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7116b8a1",
   "metadata": {},
   "source": [
    "#### All the values of our numerical variables are scaled from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e60f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52ac588",
   "metadata": {},
   "source": [
    "## Data Modelling\n",
    "\n",
    "### Splitting the data into X_train and y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac82944",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df.pop(\"Count\")\n",
    "X_train = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96dec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb6e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4e3c33",
   "metadata": {},
   "source": [
    "### We will first use Recursive feature elimination(RFE) and from there we will use our manual approach to eliminate other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaac275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define some functions so we dont have to write the same line of code again and again\n",
    "\n",
    "def VIF_score(X):\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"features\"] = X.columns\n",
    "    vif[\"VIF\"] = [round(variance_inflation_factor(X.values, i),2) for i in range(X.shape[1])]\n",
    "    vif = vif.sort_values(by = \"VIF\", ascending=False)\n",
    "    return vif\n",
    "\n",
    "\n",
    "\n",
    "def OLS_model(X_train_data, y_train = y_train, return_model = False):\n",
    "    \n",
    "    X_train_sm = sm.add_constant(X_train_data)\n",
    "    ols = OLS(y_train, X_train_sm)\n",
    "    model = ols.fit()\n",
    "    \n",
    "    if return_model:\n",
    "        return model\n",
    "    else:\n",
    "        return model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3898d9",
   "metadata": {},
   "source": [
    "### For RFE we need to use Sklearn's regression model and then proceed with the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170e6747",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db72cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(regressor, n_features_to_select = 15, step = 0.35)\n",
    "rfe_model = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84f58d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_data = pd.DataFrame()\n",
    "rfe_data[\"features\"] = X_train.columns\n",
    "rfe_data[\"Support\"] = rfe_model.support_\n",
    "rfe_data[\"Rankings\"] = rfe_model.ranking_\n",
    "rfe_data.sort_values(by = \"Rankings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6221fa2e",
   "metadata": {},
   "source": [
    "### The features above with rank 1 and support true are selected by our RFE which is best suited for our regression but we will check the p-values and vif scores to see whether they are indeed the best or a manual approach is needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788a75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[rfe_model.support_] # These are features selected by RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77f2cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe_cols = X_train.columns[rfe_model.support_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe = X_train[X_train_rfe_cols]\n",
    "X_train_rfe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e98e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLS_model(X_train_data = X_train_rfe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348c2d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIF_score(X = X_train_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d453cf",
   "metadata": {},
   "source": [
    "## Observations and Intepretation:\n",
    "- First we will emphasize features having high p-value and eliminate them\n",
    "- Eliminating certain features may alter the VIF value of some features\n",
    "- After having the p-values close to zero or atleast less than 5% (0.05) we can proceed elimianting features with high VIF values\n",
    "\n",
    "### In a broad sense we will combine RFE and manual  approach to give us the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87af459",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd2606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminating holiday due to high p-value\n",
    "\n",
    "X_train_rfe = X_train_rfe.drop(\"holiday\", axis = 1)\n",
    "X_train_rfe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230473e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLS_model(X_train_data=X_train_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125b96ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIF_score(X = X_train_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffd2372",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39ab2055",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f10f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminating humidity due to high VIf value\n",
    "X_train_rfe = X_train_rfe.drop(\"humidity\", axis = 1)\n",
    "X_train_rfe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3149b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLS_model(X_train_data=X_train_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c35af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIF_score(X = X_train_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e938fe8b",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe8bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing workingday due to its high VIF value\n",
    "X_train_rfe = X_train_rfe.drop(\"workingday\", axis = 1)\n",
    "X_train_rfe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce30be",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLS_model(X_train_data=X_train_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529bdcd2",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a629d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Monday due to its high p value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e3f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe = X_train_rfe.drop(\"Monday\", axis = 1)\n",
    "X_train_rfe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8aeabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIF_score(X = X_train_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ceaa1b",
   "metadata": {},
   "source": [
    "## Inference:\n",
    "- The p-values of all the features are close to zero and the VIFs are very well within 5 so we will consider Model 4 as our final model and proceed with the same\n",
    "- Also the variables are able to explain around 83% of variance which is a good sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2f5d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "sns.heatmap(X_train_rfe.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76ed44a",
   "metadata": {},
   "source": [
    "## Obsrvations:\n",
    "- There are no sogns of high negative or positiv correlation, the benchmark for such inference is as follows\n",
    "- We are considering anything beyond 60% as high correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf131e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = OLS_model(X_train_data=X_train_rfe, return_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b7686d",
   "metadata": {},
   "source": [
    "### We will have the following equation:\n",
    "Y(COUNT) = $ 0.299477 + (yr * 0.236298) + (temp * 0.377143) - (windspeed * 0.154046) - (spring * 0.105047) + (winter * 0.047588) - (December * 0.037435) - (January * 0.058615) + (September * 0.062998) - (Tuesday * 0.047060) - (Misty * 0.077965) - (snow_rain * 0.293356) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f6ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we go on and test our model on the test set, we need to validate some assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4012f5ce",
   "metadata": {},
   "source": [
    "## Assumptions of Linear Regressions are as follows :\n",
    "- There should exist some lienar relationship between X and Y\n",
    "- The error terms should be normall distributed\n",
    "- Independence of error terms\n",
    "- The error terms must show constant variation (Homoscedasticity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6f296d",
   "metadata": {},
   "source": [
    "### 1) We already proved that there exists some linear relationship earlier on in the notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a2b83c",
   "metadata": {},
   "source": [
    "### 2) The error terms should be normally distributed around 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd2cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe_sm = sm.add_constant(X_train_rfe)\n",
    "y_train_pred = lr_model.predict(X_train_rfe_sm)\n",
    "residuals = y_train - y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f8234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(residuals, kde = True)\n",
    "plt.title(\"Distribution of error terms\")\n",
    "plt.xlabel(\"Error terms\")\n",
    "\n",
    "plt.gcf().set_size_inches(10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe7abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f3883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709ffc54",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "- The mean of the residuals from the graph and from the calculation below validate our second assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d324262",
   "metadata": {},
   "source": [
    "## The error terms must show constant variation (Homoscedasticity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f2558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = y_train_pred, y = residuals, line_kws = {\"color\" : \"red\"})\n",
    "plt.title(\"Residuals vs predicted values(y_train_pred)\")\n",
    "plt.xlabel(\"y_train_pred\", fontdict={\"fontsize\" : 14})\n",
    "plt.ylabel(\"Residuals\", fontdict={\"fontsize\" : 14})\n",
    "plt.gcf().set_size_inches(10,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe1a6aa",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "- No visibile pattern can be noticed and this indicates that there is now lower or higher concentration of points and the residuals are evenly distributed\n",
    "- The graph above proves our 3rd and 4th assumption of linear regressions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38798728",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6901e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b784652",
   "metadata": {},
   "source": [
    "## Let's interprete these features one by one\n",
    "### -  Yr - For every increase in variable Yr the Count increases by 0.236298 units\n",
    "### -  temp - For every increase in variable Temp the Count increases by 0.377143 units\n",
    "### -  windspeed - For every increase in variable windspeed the Count decreases by 0.154046 units\n",
    "### -  spring - For every increase in variable spring the Count decreases by 0.105047 units\n",
    "### -  winter - For every increase in variable winter the Count increases by 0.047588 units\n",
    "### -  December - For every increase in variable December the Count decreases by 0.037435 units\n",
    "### -  January -  For every increase in variable January the Count decreases by 0.058615 units\n",
    "### -  September - For every increase in variable September the Count increases by 0.062998 units\n",
    "### -  Tuesday - For every increase in variable March the Count increases by 0.047060 units\n",
    "### -  misty- For every increase in variable Ideal the Count increases by 0.077965 units\n",
    "### -  snow_rain - For every increase in variable snow_rain the Count decreases by 0.293356 units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The variables matches with our analysis in EDA, as the temp decreases there is a decrease in rentals and as the temp increases we see a increase in rentals\n",
    "# the weather condition \"snow_rain\" also states tells us that people prefer riding bikes when the weather is Ideal and Misty\n",
    "# We also saw a moderately negative linear relationship of windspeed vs count and this model also conveys the same\n",
    "# For months we can see that w.r.t September the count actually shows signs of decrease for January and february which also compliments our analysis in EDA \n",
    "# The yr variable also shows a positive relationship with count; the same which we deduced\n",
    "# Our model considering the variables should be able to explain the data well cause it compliments our analysis in EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34921492",
   "metadata": {},
   "source": [
    "### We have proved all the assumption of Linear Regression and its time to actually test our model on the test set and see how it performs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03457295",
   "metadata": {},
   "source": [
    "## Evaluating our Model on the Test set\n",
    "### -  First we will scale all the values using the object (scaler) whci hwe used to scale the features of our training            set\n",
    "### -  We will split the test set into X_test and y_test\n",
    "### -  Then we will remove all the unecessary columns from our X_test and perform our final pre processing on                X-test\n",
    "### -  And finally we make our model predict the value based on the data(X_test) supplied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749f691c",
   "metadata": {},
   "source": [
    "### Scaling our Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cc183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad3295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[numerical_vars] = scaler.transform(test_df[numerical_vars])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38989cae",
   "metadata": {},
   "source": [
    "### Splitting our test set into X_test and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0f7fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_df.pop(\"Count\")\n",
    "X_test = test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25accfbf",
   "metadata": {},
   "source": [
    "### Dropping uncessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a252dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3c3c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[X_train_rfe.columns]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce4bebd",
   "metadata": {},
   "source": [
    "### Final Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sm = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e1d31",
   "metadata": {},
   "source": [
    "### Predicting and evaluating the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d977e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = lr_model.predict(X_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae23d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=y_test, y_pred = y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c42a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The accuracy of our model is {round(r2_score(y_true=y_test, y_pred = y_pred_test), 2) * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a474eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = y_test, y = y_pred_test, line_kws = {\"color\" : \"red\"})\n",
    "plt.gcf().set_size_inches(10,4)\n",
    "plt.title(\"Actual Values vs Preicted Values\")\n",
    "plt.xlabel(\"True values\")\n",
    "plt.ylabel('Predicted values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c099145",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "- Our model was able to predict well, that means the model was able to generalise on the data with 80% accuracy\n",
    "- Now we can use this model to conclude and achieve our buisness goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e510d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdacbf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The top three significant variables are: yr, temp and snow_rain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7eda68",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "- BoomBikes already had a market for Bike rental which is explained by \"const\" which is 0.2999477 which is great for the company, so they can expect growth despite little investment, the reason for this trend could be that people are trying to reduce their carbon footprint and were encouraged to rather cycle; but there are sevral other factors as well like having fun, riding bikes to school, mountain biking wheere in most cases people tend to rent theri bikes because it porves to be cheapre to them cause they dont have to incur transport charges along with other miscellaneous charges with comes along you can refer the article below which goes along with our timeline: https://www.forbes.com/sites/timnewcomb/2020/07/13/amidst-cycling-surge-sport-of-mountain-biking-seeing-increased-sales-trail-usage/?sh=2c8fcbae3ddf\n",
    "\n",
    "- Boom bikes should expand their business in the month of September as it shows the highest level of bikes rented\n",
    "\n",
    "- Boom Bike should also see that they hand out lucrative offers when the weather conditions are Ideal and temperatures slightly on the higher end cause according to the data and model this will yield maximum rental bookings, the model also concludes that  BoomBikes should also focus more offers and equipments during winters as it may help drive the rental up in those months.\n",
    "\n",
    "- From the EDA it was clear that the Fall, summer and winter had comparitively higher rental bookings, so Boom bikes must consider investing in its offers and promotion during these seasons and the months falling in these seasons.\n",
    "\n",
    "- Last but not the least BoomBikes should increase their investments every year as we can saw that the company has the potential to grow maybe not in the pandemics as people were advised to  quarantine themselves but post covid where people are more likely and eager to enjoy the outdoors and rides, the company can see a tremendous growth coupled with the scenarios above they can successfully attract more customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1f5469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada2e678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69afa5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b2ef74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021fa5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24ddaf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446d3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5614d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
